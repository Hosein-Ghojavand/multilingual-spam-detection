{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Padidar\\AppData\\Local\\Temp\\ipykernel_13388\\1089353658.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=MODEL_NAME)\n"
     ]
    }
   ],
   "source": [
    "# Load the LLM model using LangChain and Ollama\n",
    "MODEL_NAME = \"deepseek-r1:1.5b\"  # \"llama3.2\" , \"deepseek-r1:1.5b\" , \"deepseek-r1:14b\"\n",
    "llm = Ollama(model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(raw_text):\n",
    "    \"\"\"Removes the AI's thought process enclosed in <think>...</think> tags.\"\"\"\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", raw_text, flags=re.DOTALL).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess spam dataset\n",
    "spam_data = pd.read_csv('../../Data/Raw/english_sms.csv', encoding='latin1')\n",
    "spam_data = spam_data[['v1', 'v2']].rename(columns={'v1': 'label', 'v2': 'message'})\n",
    "\n",
    "def load_existing_data():\n",
    "    \"\"\"Loads spam and ham messages from the dataset.\"\"\"\n",
    "    try:\n",
    "        ham_samples = spam_data[spam_data[\"label\"] == \"ham\"][\"message\"].tolist()\n",
    "        spam_samples = spam_data[spam_data[\"label\"] == \"spam\"][\"message\"].tolist()\n",
    "        return ham_samples, spam_samples\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sms(category=\"ham\", num_samples=10, temperature=0.65, progress_bar=None):\n",
    "    \"\"\"Generates synthetic SMS messages based on real examples.\"\"\"\n",
    "    ham_examples, spam_examples = load_existing_data()\n",
    "\n",
    "    messages = []\n",
    "    for _ in range(num_samples):\n",
    "        example = random.choice(spam_examples if category == \"spam\" else ham_examples)\n",
    "        \n",
    "        # Separate prompts for ham and spam\n",
    "        if category == \"ham\":\n",
    "            prompt = (\n",
    "                f\"You are an AI assistant that generates a **realistic ham SMS message**. \"\n",
    "                f\"The message should be similar to: \\\"{example}\\\"\"\n",
    "                \"\\n### Guidelines:\\n\"\n",
    "                \"1. Keep the message **short** (under 25 words) and **natural**.\\n\"\n",
    "                \"2. Use **casual, conversational language** that fits a real SMS between friends or family.\\n\"\n",
    "                \"3. Avoid using placeholders like [Name] or [Date]; instead, use **common names and realistic references**.\\n\"\n",
    "                \"4. The message should feel like a **genuine** conversation, with personal, relatable content.\\n\"\n",
    "                \"5. Do **not** include meta-comments, explanations, or unnecessary details.\\n\"\n",
    "                \"6. Wrap the generated message in **double quotes**, and do not add extra text.\\n\"\n",
    "                \"\\nNow, generate the SMS message.\"\n",
    "            )\n",
    "        elif category == \"spam\":\n",
    "            prompt = (\n",
    "                f\"You are an AI assistant that generates a **realistic spam SMS message**. \"\n",
    "                f\"The message should be similar to: \\\"{example}\\\"\"\n",
    "                \"\\n### Guidelines:\\n\"\n",
    "                \"1. Keep the message **short** (under 25 words) and **realistic**.\\n\"\n",
    "                \"2. Use **casual, convincing language** that fits a real spam SMS someone might receive.\\n\"\n",
    "                \"3. Avoid using placeholders like [Name] or [Date]; instead, use **common names and realistic references**.\\n\"\n",
    "                \"4. The message should include a **promotional offer, prize claim, fake urgency, or financial lure**.\\n\"\n",
    "                \"5. Create a sense of urgency, but avoid using overtly fake or misleading terms like â€˜fakeâ€™ or â€˜scamâ€™.\\n\"\n",
    "                \"6. Use a **realistic-sounding company name** or a vague sender for authenticity (e.g., â€˜XYZ Corp.â€™ or â€˜Promo Teamâ€™).\\n\"\n",
    "                \"7. Wrap the generated message in **double quotes**, and do not add extra text.\\n\"\n",
    "                \"\\nNow, generate the SMS message.\"\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid category. Choose 'ham' or 'spam'.\")\n",
    "\n",
    "        try:\n",
    "            response = llm.invoke(prompt, temperature=temperature).strip()\n",
    "            messages.append(clean_message(response))\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating message: {e}\")\n",
    "            messages.append(\"[ERROR] Failed to generate message\")\n",
    "\n",
    "    # Update the progress bar after the batch is complete\n",
    "    if progress_bar:\n",
    "        progress_bar.update(num_samples)\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(num_ham=500, num_spam=500, output_file=\"../../Data/Synthetic/synthetic_english_sms.csv\", batch_size=2):\n",
    "    \"\"\"Generates a synthetic SMS dataset and saves it incrementally as a CSV file.\"\"\"\n",
    "   \n",
    "    # Initialize or load existing dataset\n",
    "    if os.path.exists(output_file):\n",
    "        data = pd.read_csv(output_file)\n",
    "        print(f\"Loaded existing dataset with {len(data)} samples.\")\n",
    "    else:\n",
    "        data = pd.DataFrame(columns=[\"message\", \"label\"])\n",
    "        print(\"No existing dataset found. Starting fresh.\")\n",
    "\n",
    "    # Track progress\n",
    "    ham_generated = len(data[data[\"label\"] == \"ham\"])\n",
    "    spam_generated = len(data[data[\"label\"] == \"spam\"])\n",
    "\n",
    "    # Progress bars for ham and spam generation\n",
    "    with tqdm(total=num_ham, initial=ham_generated, desc=\"Generating Ham Messages\", unit=\"msg\") as ham_progress:\n",
    "        while ham_generated < num_ham:\n",
    "            try:\n",
    "                ham_messages = generate_sms(\n",
    "                    \"ham\", min(batch_size, num_ham - ham_generated)\n",
    "                )\n",
    "                new_data = pd.DataFrame({\n",
    "                    \"message\": ham_messages,\n",
    "                    \"label\": [\"ham\"] * len(ham_messages)\n",
    "                })\n",
    "                data = pd.concat([data, new_data], ignore_index=True)\n",
    "                data.to_csv(output_file, index=False)  # Save progress incrementally\n",
    "                ham_generated += len(ham_messages)\n",
    "                ham_progress.update(len(ham_messages))\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating ham messages: {e}\")\n",
    "                break\n",
    "\n",
    "    with tqdm(total=num_spam, initial=spam_generated, desc=\"Generating Spam Messages\", unit=\"msg\") as spam_progress:\n",
    "        while spam_generated < num_spam:\n",
    "            try:\n",
    "                spam_messages = generate_sms(\n",
    "                    \"spam\", min(batch_size, num_spam - spam_generated)\n",
    "                )\n",
    "                new_data = pd.DataFrame({\n",
    "                    \"message\": spam_messages,\n",
    "                    \"label\": [\"spam\"] * len(spam_messages)\n",
    "                })\n",
    "                data = pd.concat([data, new_data], ignore_index=True)\n",
    "                data.to_csv(output_file, index=False)  # Save progress incrementally\n",
    "                spam_generated += len(spam_messages)\n",
    "                spam_progress.update(len(spam_messages))\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating spam messages: {e}\")\n",
    "                break\n",
    "\n",
    "    # Shuffle the dataset before saving\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    data.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Dataset generation completed. Saved to {output_file}. Total samples: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing dataset with 1020 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Ham Messages: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [08:52<00:00,  5.92s/msg]\n",
      "Generating Spam Messages:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 512/600 [00:11<08:28,  5.77s/msg]"
     ]
    }
   ],
   "source": [
    "# Generate dataset\n",
    "generate_dataset(num_ham=600, num_spam=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Where have u been hiding?\"  \\n\"I was hiding i...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I'm meeting you at [park/restaurant] with a l...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Dear Matthew, call [09063440451] from a landl...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Where are you? How long until we meet?\"</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"You have an important customer service announ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>\"Hi there! ðŸŽ‰ Happy dancing with friends. All s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>\"URGENT! XYZ Corp. trying to contact John. Tod...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>\"I just heard from [Friend's Name], and I trul...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>\"Hi [Name], I just wanted to check if anyone w...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>\"XYZ Corp. Hereâ€™s your prize! Call me at 07123...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message label\n",
       "0     \"Where have u been hiding?\"  \\n\"I was hiding i...   ham\n",
       "1     \"I'm meeting you at [park/restaurant] with a l...   ham\n",
       "2     \"Dear Matthew, call [09063440451] from a landl...  spam\n",
       "3              \"Where are you? How long until we meet?\"   ham\n",
       "4     \"You have an important customer service announ...  spam\n",
       "...                                                 ...   ...\n",
       "1015  \"Hi there! ðŸŽ‰ Happy dancing with friends. All s...   ham\n",
       "1016  \"URGENT! XYZ Corp. trying to contact John. Tod...  spam\n",
       "1017  \"I just heard from [Friend's Name], and I trul...   ham\n",
       "1018  \"Hi [Name], I just wanted to check if anyone w...  spam\n",
       "1019  \"XYZ Corp. Hereâ€™s your prize! Call me at 07123...  spam\n",
       "\n",
       "[1020 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic = pd.read_csv(\"../../Data/Synthetic/synthetic_english_sms.csv\")\n",
    "synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test improved prompt generation by generating one message per category\n",
    "# def test_prompt_engineering():\n",
    "#     print(\"Testing improved prompt engineering:\")\n",
    "#     ham_message = generate_sms(\"ham\", num_samples=1)[0]\n",
    "#     spam_message = generate_sms(\"spam\", num_samples=1)[0]\n",
    "    \n",
    "#     print(\"\\nGenerated Ham Message:\")\n",
    "#     print(ham_message)\n",
    "#     print(\"\\nGenerated Spam Message:\")\n",
    "#     print(spam_message)\n",
    "\n",
    "\n",
    "\n",
    "# test_prompt_engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(synthetic)):\n",
    "#     print(f\"{i + 1}.[{synthetic[\"label\"][i]}]: {synthetic[\"message\"][i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
