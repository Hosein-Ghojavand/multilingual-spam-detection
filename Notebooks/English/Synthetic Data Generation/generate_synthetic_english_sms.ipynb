{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Padidar\\AppData\\Local\\Temp\\ipykernel_13388\\1089353658.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=MODEL_NAME)\n"
     ]
    }
   ],
   "source": [
    "# Load the LLM model using LangChain and Ollama\n",
    "MODEL_NAME = \"deepseek-r1:1.5b\"  # \"llama3.2\" , \"deepseek-r1:1.5b\" , \"deepseek-r1:14b\"\n",
    "llm = Ollama(model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(raw_text):\n",
    "    \"\"\"Removes the AI's thought process enclosed in <think>...</think> tags.\"\"\"\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", raw_text, flags=re.DOTALL).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess spam dataset\n",
    "spam_data = pd.read_csv('../../Data/Raw/english_sms.csv', encoding='latin1')\n",
    "spam_data = spam_data[['v1', 'v2']].rename(columns={'v1': 'label', 'v2': 'message'})\n",
    "\n",
    "def load_existing_data():\n",
    "    \"\"\"Loads spam and ham messages from the dataset.\"\"\"\n",
    "    try:\n",
    "        ham_samples = spam_data[spam_data[\"label\"] == \"ham\"][\"message\"].tolist()\n",
    "        spam_samples = spam_data[spam_data[\"label\"] == \"spam\"][\"message\"].tolist()\n",
    "        return ham_samples, spam_samples\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sms(category=\"ham\", num_samples=10, temperature=0.65, progress_bar=None):\n",
    "    \"\"\"Generates synthetic SMS messages based on real examples.\"\"\"\n",
    "    ham_examples, spam_examples = load_existing_data()\n",
    "\n",
    "    messages = []\n",
    "    for _ in range(num_samples):\n",
    "        example = random.choice(spam_examples if category == \"spam\" else ham_examples)\n",
    "        \n",
    "        # Separate prompts for ham and spam\n",
    "        if category == \"ham\":\n",
    "            prompt = (\n",
    "                f\"You are an AI assistant that generates a **realistic ham SMS message**. \"\n",
    "                f\"The message should be similar to: \\\"{example}\\\"\"\n",
    "                \"\\n### Guidelines:\\n\"\n",
    "                \"1. Keep the message **short** (under 25 words) and **natural**.\\n\"\n",
    "                \"2. Use **casual, conversational language** that fits a real SMS between friends or family.\\n\"\n",
    "                \"3. Avoid using placeholders like [Name] or [Date]; instead, use **common names and realistic references**.\\n\"\n",
    "                \"4. The message should feel like a **genuine** conversation, with personal, relatable content.\\n\"\n",
    "                \"5. Do **not** include meta-comments, explanations, or unnecessary details.\\n\"\n",
    "                \"6. Wrap the generated message in **double quotes**, and do not add extra text.\\n\"\n",
    "                \"\\nNow, generate the SMS message.\"\n",
    "            )\n",
    "        elif category == \"spam\":\n",
    "            prompt = (\n",
    "                f\"You are an AI assistant that generates a **realistic spam SMS message**. \"\n",
    "                f\"The message should be similar to: \\\"{example}\\\"\"\n",
    "                \"\\n### Guidelines:\\n\"\n",
    "                \"1. Keep the message **short** (under 25 words) and **realistic**.\\n\"\n",
    "                \"2. Use **casual, convincing language** that fits a real spam SMS someone might receive.\\n\"\n",
    "                \"3. Avoid using placeholders like [Name] or [Date]; instead, use **common names and realistic references**.\\n\"\n",
    "                \"4. The message should include a **promotional offer, prize claim, fake urgency, or financial lure**.\\n\"\n",
    "                \"5. Create a sense of urgency, but avoid using overtly fake or misleading terms like ‘fake’ or ‘scam’.\\n\"\n",
    "                \"6. Use a **realistic-sounding company name** or a vague sender for authenticity (e.g., ‘XYZ Corp.’ or ‘Promo Team’).\\n\"\n",
    "                \"7. Wrap the generated message in **double quotes**, and do not add extra text.\\n\"\n",
    "                \"\\nNow, generate the SMS message.\"\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid category. Choose 'ham' or 'spam'.\")\n",
    "\n",
    "        try:\n",
    "            response = llm.invoke(prompt, temperature=temperature).strip()\n",
    "            messages.append(clean_message(response))\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating message: {e}\")\n",
    "            messages.append(\"[ERROR] Failed to generate message\")\n",
    "\n",
    "    # Update the progress bar after the batch is complete\n",
    "    if progress_bar:\n",
    "        progress_bar.update(num_samples)\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(num_ham=500, num_spam=500, output_file=\"../../Data/Synthetic/synthetic_english_sms.csv\", batch_size=2):\n",
    "    \"\"\"Generates a synthetic SMS dataset and saves it incrementally as a CSV file.\"\"\"\n",
    "   \n",
    "    # Initialize or load existing dataset\n",
    "    if os.path.exists(output_file):\n",
    "        data = pd.read_csv(output_file)\n",
    "        print(f\"Loaded existing dataset with {len(data)} samples.\")\n",
    "    else:\n",
    "        data = pd.DataFrame(columns=[\"message\", \"label\"])\n",
    "        print(\"No existing dataset found. Starting fresh.\")\n",
    "\n",
    "    # Track progress\n",
    "    ham_generated = len(data[data[\"label\"] == \"ham\"])\n",
    "    spam_generated = len(data[data[\"label\"] == \"spam\"])\n",
    "\n",
    "    # Progress bars for ham and spam generation\n",
    "    with tqdm(total=num_ham, initial=ham_generated, desc=\"Generating Ham Messages\", unit=\"msg\") as ham_progress:\n",
    "        while ham_generated < num_ham:\n",
    "            try:\n",
    "                ham_messages = generate_sms(\n",
    "                    \"ham\", min(batch_size, num_ham - ham_generated)\n",
    "                )\n",
    "                new_data = pd.DataFrame({\n",
    "                    \"message\": ham_messages,\n",
    "                    \"label\": [\"ham\"] * len(ham_messages)\n",
    "                })\n",
    "                data = pd.concat([data, new_data], ignore_index=True)\n",
    "                data.to_csv(output_file, index=False)  # Save progress incrementally\n",
    "                ham_generated += len(ham_messages)\n",
    "                ham_progress.update(len(ham_messages))\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating ham messages: {e}\")\n",
    "                break\n",
    "\n",
    "    with tqdm(total=num_spam, initial=spam_generated, desc=\"Generating Spam Messages\", unit=\"msg\") as spam_progress:\n",
    "        while spam_generated < num_spam:\n",
    "            try:\n",
    "                spam_messages = generate_sms(\n",
    "                    \"spam\", min(batch_size, num_spam - spam_generated)\n",
    "                )\n",
    "                new_data = pd.DataFrame({\n",
    "                    \"message\": spam_messages,\n",
    "                    \"label\": [\"spam\"] * len(spam_messages)\n",
    "                })\n",
    "                data = pd.concat([data, new_data], ignore_index=True)\n",
    "                data.to_csv(output_file, index=False)  # Save progress incrementally\n",
    "                spam_generated += len(spam_messages)\n",
    "                spam_progress.update(len(spam_messages))\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating spam messages: {e}\")\n",
    "                break\n",
    "\n",
    "    # Shuffle the dataset before saving\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    data.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Dataset generation completed. Saved to {output_file}. Total samples: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing dataset with 1020 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Ham Messages: 100%|██████████| 600/600 [08:52<00:00,  5.92s/msg]\n",
      "Generating Spam Messages:  85%|████████▌ | 512/600 [00:11<08:28,  5.77s/msg]"
     ]
    }
   ],
   "source": [
    "# Generate dataset\n",
    "generate_dataset(num_ham=600, num_spam=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Where have u been hiding?\"  \\n\"I was hiding i...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I'm meeting you at [park/restaurant] with a l...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Dear Matthew, call [09063440451] from a landl...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Where are you? How long until we meet?\"</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"You have an important customer service announ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>\"Hi there! 🎉 Happy dancing with friends. All s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>\"URGENT! XYZ Corp. trying to contact John. Tod...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>\"I just heard from [Friend's Name], and I trul...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>\"Hi [Name], I just wanted to check if anyone w...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>\"XYZ Corp. Here’s your prize! Call me at 07123...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message label\n",
       "0     \"Where have u been hiding?\"  \\n\"I was hiding i...   ham\n",
       "1     \"I'm meeting you at [park/restaurant] with a l...   ham\n",
       "2     \"Dear Matthew, call [09063440451] from a landl...  spam\n",
       "3              \"Where are you? How long until we meet?\"   ham\n",
       "4     \"You have an important customer service announ...  spam\n",
       "...                                                 ...   ...\n",
       "1015  \"Hi there! 🎉 Happy dancing with friends. All s...   ham\n",
       "1016  \"URGENT! XYZ Corp. trying to contact John. Tod...  spam\n",
       "1017  \"I just heard from [Friend's Name], and I trul...   ham\n",
       "1018  \"Hi [Name], I just wanted to check if anyone w...  spam\n",
       "1019  \"XYZ Corp. Here’s your prize! Call me at 07123...  spam\n",
       "\n",
       "[1020 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic = pd.read_csv(\"../../Data/Synthetic/synthetic_english_sms.csv\")\n",
    "synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test improved prompt generation by generating one message per category\n",
    "# def test_prompt_engineering():\n",
    "#     print(\"Testing improved prompt engineering:\")\n",
    "#     ham_message = generate_sms(\"ham\", num_samples=1)[0]\n",
    "#     spam_message = generate_sms(\"spam\", num_samples=1)[0]\n",
    "    \n",
    "#     print(\"\\nGenerated Ham Message:\")\n",
    "#     print(ham_message)\n",
    "#     print(\"\\nGenerated Spam Message:\")\n",
    "#     print(spam_message)\n",
    "\n",
    "\n",
    "\n",
    "# test_prompt_engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(synthetic)):\n",
    "#     print(f\"{i + 1}.[{synthetic[\"label\"][i]}]: {synthetic[\"message\"][i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
